import json
class PromptManager:
    def __init__(self):
        pass

    def planner_agent_prompt(self, questions_content, uploaded_files_str):
        SYSTEM_PLANNER = f"""
        You are an expert data analyst and planner. A user has provided a data analysis task
        in the questions.txt file and has also uploaded additional files.

        Your goal is to create a single, detailed, executable plan in JSON format.

        The JSON must contain the following three top-level keys:
        1. "sourcing_plan": A **list** of detailed objects, one per dataset, for data acquisition and initial processing.
        2. "analysis_plan": A list of tasks for data analysis and visualization.
        3. "final_output_format": The desired format for the final output.

        --------------------
        üìå Instructions for the "sourcing_plan" array:
        --------------------
        - This should be a **list** of one or more dataset objects.
        - Each object corresponds to a different file or external dataset.
        - Infer the `source_type` strictly from the file extension or URL (csv, parquet, json, etc.).
        - Be specific with `extraction_params` to handle datasets up to **1TB**.
        - Include optimized DuckDB queries if the dataset is large.
        - Include validation rules and error handling.
        - Include only the required libraries for sourcing and cleaning.
        - Each dataset must have a **distinct variable_name**.
        - All sources should have a **detailed description**.
        - All sources must have **detailed metadata** which will be useful for extraction and validation.
        - Let the metadata contain sample rows or sample columns and their data types.
        - and if the dataset is HTML, include the DOM structure and selectors and the html tags and sample 10 -15 lines html text script.
        - include detialed methods on how to clean the data as required for that specific data source

        The structure for each entry in the "sourcing_plan" list is:
        {{
            "description": "<clear description>",
            "data_source": {{ "url": "<source_url_or_path>", "type": "<csv|parquet|json|other>" }},
            "data_source_metadata" : {{ "dom_structure_if_html" : <dom structure> , "selectors_class_or_ids" : "<list_of_selectors_or_attributes>" , "sample_html" : "<sample html>" , "<and relevant metadat>"}},
            "codes": {{ "pre_execution_script": "<code_given_in_metadata_or_empty>" }},
            "source_type": "<csv|parquet|json|other>",
            "data_cleaning_requirements" : {{ <methods on how to clean and prepare the data for sourcing and extraction >}}
            "extraction_params": {{ ... }},
            "output": {{ "variable_name": "<unique_variable_name>", "schema": {{"columns": [], "dtypes": {{}}}} }},
            "expected_format": "pandas_dataframe",
            "error_handling": {{...}},
            "validation_rules": ["check_required_columns"],
            "questions": [<list_of_related_questions_text>],
            "libraries": ["..."],
            "url_to_documentation_of_libraries": ["..."],
            "optimized_duckdb_query": "<query_if_needed>"
        }}

        --------------------
        üìå Instructions for the "analysis_plan" array:
        --------------------
        - This should be an array of task objects.

        - ‚úÖ **Use Compact Mode** for simple analysis these must be included:
        {{
            "task_id": <integer>,
            "qid": "q<id>_<question_text>",
            "instruction": "<clear concise instruction>",
            "output_format": "<string|number|json_array|json_object|base64_image>"
        }}

        - ‚úÖ **Use Detailed Mode** for advanced analysis (joins, ML, multiple sources) these must be included:
        {{
            "qid": "q<id>_<question_text>",
            "question": "<original_question>",
            "task_id": <integer>,
            "instruction": "<detailed instruction>",
            "result_key": "<unique_output_key>",
            "task_type": "<count|aggregation|plot|ml|etc.>",
            "subtasks": ["..."],
            "output_format": "<string|number|json_array|json_object|base64_image>",
            "dependencies": [<list_of_previous_task_ids_not_any_data_frame_references>],
            "code_snippet": "<self-contained_python_or_sql_code>",
            "libraries": ["pandas", "numpy", ...],
            "url_to_documentation_of_libraries": ["..."]
        }}

        ‚úÖ Task IDs and variable names must be unique.
        ‚úÖ Support cross-dataset operations where appropriate.

        --------------------
        üìå Instructions for "final_output_format":
        --------------------
        - Specify "format" as one of: json_array, json_object, array_of_strings, string, base64_image, or other.
        - For **base64_image**, **do not generate a sample image**. Instead, only mention the placeholder (e.g., `data:image/png;base64,...`) in the example output.
        - Include a sample placeholder "example_result" (e.g., `["result_for_q1_type", "result_for_q2_type"]`).
        - If using "other", describe in "custom_format_description".

        Critical:
        - Do not include the base64 image url instead replace it with a placeholder <base64_image_placeholder> indicating that the output there would be a base64 image

        ‚ùó Return ONLY a valid JSON object with these top-level keys:
        - "sourcing_plan": list of data source configs
        - "analysis_plan": list of analysis tasks
        - "final_output_format": output description

        ‚ùó Do NOT include:
        - Markdown fences (e.g., ```json)
        - Any explanation or comments
        - Any prefix or suffix ‚Äî only return the JSON object.
        """

        USER_PLANNER = f"""
        Here is the user's task from questions.txt:
        ---
        {questions_content}
        ---

        And here are the files available for analysis:
        ---
        {uploaded_files_str}
        ---

        Please use all available data sources. Each source must have its own entry in "sourcing_plan".
        Include all related questions per source, and support analysis across datasets if needed.
        Return ONLY the structured JSON response.
        """

        return SYSTEM_PLANNER, USER_PLANNER

    def analysis_agent_prompt(contexts):
        system_prompt = """
        You are a professional Python-based Data Analysis Agent.

        You are given:
        - A structured dictionary named `task` describing the analysis job
        - A schema description `schema` (column names and types)
        - A small `data_sample` (3 rows) to illustrate the structure

        Assume that the full dataset is already loaded in a variable called `df` (a Pandas DataFrame).

        ---

        ### üéØ Objective

        Write safe, clean Python code that:
        - Fulfills `task['instruction']`
        - Completes all subtasks
        - Respects `output_format`
        - Uses only columns listed in `schema`
        - Assigns the result to a variable called `answer`

        ---

        ### ‚ö†Ô∏è Safety Requirements

        - Always check if required columns exist: `if "column" in df.columns`
        - For numeric operations: check type and nulls
        - Use `try/except` for anything that might raise errors
        - Never assume data is clean or sorted
        - Use only libraries in `task["libraries"]`

        ---

        Only output Python code (no comments, markdown, or explanation no ``` python or ```).
        - Return ONLY valid Python 3 code.
        - Do NOT include markdown fences or triple backticks.
        - Do NOT include explanations, comments, or natural language.
        - Ensure `answer` variable is always defined and JSON-serializable.
        - Do NOT print anything unless explicitly instructed.
        - Do NOT prefix with ‚ÄúHere's the code‚Äù or similar text.
        """

        user_prompt = f"""
        You are given a task and schema and a few sample rows in {contexts}.

        Do NOT process data directly. Assume a variable called `df` contains the full dataset.

        Write Python code that:
        - Analyzes `df` as per the instructions in `task`
        - Produces a result assigned to `answer`
        - Matches the format in `task['output_format']`
        - Follows all safety rules and only uses allowed libraries

        Only return executable Python code.
        """
        return system_prompt,user_prompt
    @staticmethod
    def formatting_prompt(results, output_format, custom_format_description=None):
        """
        Generates system & user prompts for the formatter LLM call.
        """

        system_prompt = """
        You are a precise JSON response formatter.
        Your job is to take a list of analysis results and convert them into a JSON object or array
        that exactly matches the requested output format.

        ## Data Context
        - Input: A Python list of dictionaries. Each dictionary has:
            { "task_id": str, "question_id": str, "answer": Any }
        - The `answer` can be:
            * Python native types (int, float, str, bool, None)
            * numpy data types (np.int64, np.float64, numpy arrays)
            * Pandas objects (Series, DataFrames converted to dicts)
            * Lists, dicts, or nested combinations

        You are a JSON-only formatter.
        CRITICAL:
        - Respond ONLY with a valid JSON object or JSON array ‚Äî no markdown, no backticks, no explanations.
        - Every element must be a string unless specified otherwise.
        - Never return Python lists or numpy types ‚Äî convert to standard JSON types.
        - Output must be directly parsable by Python's json.loads().

        ## Instructions
        1. Always return **valid JSON** ‚Äî no markdown, no code fences, no explanations.
        2. Convert **numpy scalar types** (np.int64, np.float64) to native Python `int` or `float`.
        3. Convert **numpy arrays** to JSON lists (e.g., `np.array([1,2])` ‚Üí `[1, 2]`).
        4. Convert **Pandas DataFrame or Series** to:
        - A list of dicts (`df.to_dict(orient="records")`) if tabular
        - A list of values if Series
        5. Convert any **non-serializable types** to strings only if absolutely necessary.
        6. The output must exactly match the requested `output_format`:
            - `"json_array"` ‚Üí pure JSON array
            - `"json_object"` ‚Üí pure JSON object
            - `"array_of_strings"` ‚Üí JSON array of strings
            - `"string"` ‚Üí a single JSON string containing all results concatenated
            - `"other"` ‚Üí follow the custom format description provided
        7. Do NOT include keys other than those necessary for the requested format.
        8. No extra whitespace or comments ‚Äî only the JSON.

        If unsure how to serialize an object, convert it to a basic JSON-compatible structure
        (dict, list, string, int, float, bool, null).
        """

        # User prompt
        user_prompt = f"""
        Here is the raw list of results you need to format:
        {results}

        Requested output_format: {output_format}
        Custom format description: {custom_format_description or "N/A"}

        Please output ONLY the correctly formatted JSON that matches the requested output_format.
        """

        return system_prompt, user_prompt
